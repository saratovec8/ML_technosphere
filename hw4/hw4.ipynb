{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №4 - Градиентный бустинг\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 21 декабря 2020, 08:30   \n",
    "**Штраф за опоздание:** -2 балла после 08:30 21 декабря, -4 балла после 08:30 28 декабря, -6 баллов после 08:30 04 янва, -8 баллов после 08:30 11 января.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0220, Задание 4] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Считаем производные для функций потерь (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем реализовать градиентный бустинг для 3 функций потерь:\n",
    "\n",
    "1) MSE  $L(a(x_i), y_i) = (y_i - a(x_i)) ^ 2$\n",
    "\n",
    "2) Экспоненциальная  $L(a(x_i), y_i) = exp( -a(x_i) y_i), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "3) Логистическая  $L(a(x_i), y_i) = \\log (1 + exp( -a(x_i) y_i)), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "где $a(x_i)$ предсказание бустинга на итом объекте. \n",
    "\n",
    "Для каждой функции потерь напишите таргет, на который будет настраиваться каждое дерево в бустинге. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ответ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На $k$-й итерации для всех $i$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) MSE $-\\dfrac{\\partial L}{\\partial F}(F_{k-1}(x_i), y_i)=  -2*(F_{k-1}(x_i) - y_i) = 2*(y_i - F_{k-1}(x_i)) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Экспоненциальная $ -\\dfrac{\\partial L}{\\partial F}(F_{k-1}(x_i), y_i)=-\\exp(-y_i F_{k-1}(x_i))(-y_i) =  y_i*\\exp(-y_i F_{k-1}(x_i))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Логистическая $ -\\dfrac{\\partial L}{\\partial F}(F_{k-1}(x_i), y_i) = \\dfrac{y_i*\\exp(-y_i F_{k-1}(x_i))}{1 + \\exp(-y_i F_{k-1}(x_i)} = \\dfrac{y_i}{1 + \\exp(y_i F_{k-1}(x_i))}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Реализуем градиентный бустинг (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте класс градиентного бустинга для классификации. Ваша реализация бустинга должна работать по точности не более чем на 5 процентов хуже чем GradientBoostingClassifier из sklearn. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Детали реализации:\n",
    "\n",
    "-- должно поддерживаться 3 функции потерь\n",
    "\n",
    "-- сами базовые алгоритмы(деревья, линейные модели и тп) реализовать не надо, просто возьмите готовые из sklearn\n",
    "\n",
    "-- в качестве функции потерь для построения одного дерева используйте MSE\n",
    "\n",
    "-- шаг в бустинге можно не подбирать, можно брать константный\n",
    "\n",
    "-- можно брать разные модели в качестве инициализации бустинга\n",
    "\n",
    "-- должны поддерживаться следующие параметры:\n",
    "\n",
    "а) число итераций\n",
    "б) размер шага\n",
    "в) процент случайных фичей при построении одного дерева\n",
    "д) процент случайных объектов при построении одного дерева\n",
    "е) параметры базового алгоритма (передавайте через **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGradientBoostingClassifier:\n",
    "\n",
    "    def __init__(self, loss='MSE', learning_rate=0.1, n_estimators=100, colsample=1.0, subsample=1.0, *args, **kwargs):\n",
    "        \n",
    "        self.loss = loss\n",
    "        self.F = list() \n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_estimators = n_estimators\n",
    "        self.colsample = colsample\n",
    "        self.subsample = subsample\n",
    "        self.base_args = args\n",
    "        self.base_kwargs = kwargs\n",
    "    \n",
    "    def init_model(self, init_model,X,y):\n",
    "        N = X.shape[0]\n",
    "        M = X.shape[1]\n",
    "        if init_model is not None:\n",
    "            init_model.fit(X,y)\n",
    "            self.F_l = init_model.predict(X).astype('float64')\n",
    "            self.F.append((1.0, init_model, np.arange(M)))\n",
    "        else:\n",
    "            self.F_l = np.zeros(shape=N)\n",
    "                                    \n",
    "   \n",
    "    def fit(self, X, y, base_model=DecisionTreeRegressor, init_model=None):\n",
    "        \n",
    "        self.F_l = None         \n",
    "        self.init_model(init_model, X, y)\n",
    "        \n",
    "        N = X.shape[0]\n",
    "        M = X.shape[1]\n",
    "        a = np.tile(np.arange(N), M).reshape(-1,N).T\n",
    "        b = np.tile(np.arange(M), N).reshape(-1,M)\n",
    "        \n",
    "        n_x = int(self.subsample * N)\n",
    "        n_f = int(self.colsample * M)\n",
    "        \n",
    "        for step in range(self.n_estimators):\n",
    "            model = base_model(*self.base_args, **self.base_kwargs)\n",
    "                                \n",
    "            x = np.random.choice(N, n_x)\n",
    "            feature = np.sort(np.random.choice(M, n_f, replace=False))\n",
    "                                    \n",
    "            smpl = X[a[x, :n_f], b[:n_x, feature]]\n",
    "                                    \n",
    "            last = self.F_l[x]\n",
    "            y_i = y[x]\n",
    "                                    \n",
    "            if self.loss == 'MSE':\n",
    "                delta = 2 * (y_i - last)                        \n",
    "                                    \n",
    "            if self.loss == 'EXP':\n",
    "                delta = y_i * np.exp(-y_i * last)\n",
    "                                    \n",
    "            if self.loss == 'LOG':\n",
    "                delta = y_i / (np.exp(y_i * last) + 1.0)\n",
    "   \n",
    "                                    \n",
    "            model.fit(smpl, delta)\n",
    "            self.F.append((self.learning_rate, model, feature))\n",
    "            self.F_l += self.learning_rate * model.predict(X[:, feature])\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        \n",
    "        N = X.shape[0]\n",
    "        M = X.shape[1]\n",
    "        a = np.tile(np.arange(N), M).reshape(-1,N).T\n",
    "        b = np.tile(np.arange(M), N).reshape(-1,M)\n",
    "        predict  = 0\n",
    "        for rate, model, feature in self.F:\n",
    "            smpl = X[a[:, :feature.shape[0]], b[:, feature]]\n",
    "            predict += rate * model.predict(smpl)\n",
    "        if self.loss == 'MSE':\n",
    "            return (predict + 0.5).astype('int')\n",
    "        if self.loss == 'EXP':\n",
    "            return 2 * (predict > 0).astype('int') - 1\n",
    "        if self.loss == 'LOG':\n",
    "            return 2 * (predict > 0).astype('int') - 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyGradientBoostingClassifier()\n",
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "my_clf.fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбираем параметры (2 балла)\n",
    "\n",
    "Давайте попробуем применить Ваш бустинг для предсказаний цены домов в Калифорнии. Чтобы можно было попробовтаь разные функции потерь, переведем по порогу таргет в 2 класса: дорогие и дешевые дома."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задании нужно\n",
    "\n",
    "1) Построить график точности в зависимости от числа итераций на валидации.\n",
    "\n",
    "2) Подобрать оптимальные параметры Вашего бустинга на валидации. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8) (20640,)\n"
     ]
    }
   ],
   "source": [
    "# Превращаем регрессию в классификацию\n",
    "y = (y > 2.0).astype(int)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_1 = 2 * y - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "kFold = KFold(n_splits=5, shuffle=False)\n",
    "result = []\n",
    "for n_estimators in  np.arange(50, 200, 10):\n",
    "    res = []\n",
    "    for train, test in kFold.split(X):\n",
    "        \n",
    "        X_train, X_test,y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "        \n",
    "        scaler = StandardScaler()\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        \n",
    "        myclf = MyGradientBoostingClassifier(n_estimators=n_estimators, max_depth=6)\n",
    "        myclf.fit(X_train, y_train)\n",
    "\n",
    "        X_test = scaler.transform(X_test)\n",
    "        pred = myclf.predict(X_test)\n",
    "        \n",
    "        res.append(accuracy_score(y_test, pred))\n",
    "        \n",
    "    result.append(np.mean(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_ = np.arange(50, 200, 10)\n",
    "y_ = result\n",
    "plt.plot(x_,y_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "kFold = KFold(n_splits=5, shuffle=False)\n",
    "result = []\n",
    "for loss in ['LOG', 'EXP', 'MSE'] :\n",
    "    res = []\n",
    "    for train, test in kFold.split(X):\n",
    "        if loss == 'MSE':\n",
    "            X_train, X_test,y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "        if loss == 'EXP': \n",
    "            X_train, X_test,y_train, y_test = X[train], X[test], y_1[train], y_1[test]\n",
    "        if loss == 'LOG': \n",
    "            X_train, X_test,y_train, y_test = X[train], X[test], y_1[train], y_1[test]\n",
    "    \n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        \n",
    "        myclf = MyGradientBoostingClassifier(n_estimators=110,loss=loss,max_depth=6)\n",
    "      \n",
    "            \n",
    "        myclf.fit(X_train, y_train)\n",
    "\n",
    "        X_test = scaler.transform(X_test)\n",
    "        pred = myclf.predict(X_test)\n",
    "        \n",
    "        res.append(accuracy_score(y_test, pred))\n",
    "        \n",
    "    result.append((loss,np.mean(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('LOG', 0.8303779069767442),\n",
       " ('EXP', 0.8400678294573642),\n",
       " ('MSE', 0.8322674418604652)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "kFold = KFold(n_splits=5, shuffle=False)\n",
    "result = []\n",
    "for max_depth in range(4,10) :\n",
    "    res = []\n",
    "    for train, test in kFold.split(X):\n",
    "        \n",
    "        X_train, X_test,y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        \n",
    "        myclf = MyGradientBoostingClassifier(n_estimators=110,\n",
    "                                             learning_rate=0.05,\n",
    "                                             max_depth=max_depth)\n",
    "      \n",
    "        myclf.fit(X_train, y_train)\n",
    "\n",
    "        X_test = scaler.transform(X_test)\n",
    "        pred = myclf.predict(X_test)\n",
    "        \n",
    "        res.append(accuracy_score(y_test, pred))\n",
    "        \n",
    "    result.append((max_depth,np.mean(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4, 0.8295542635658915),\n",
       " (5, 0.8376937984496123),\n",
       " (6, 0.8426356589147288),\n",
       " (7, 0.8426356589147288),\n",
       " (8, 0.8345930232558139),\n",
       " (9, 0.8378391472868219)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "kFold = KFold(n_splits=5, shuffle=False)\n",
    "result = []\n",
    "\n",
    "for learning_rate in  [0.05, 0.1, 0.3, 0.5]:\n",
    "    res = []\n",
    "    for train, test in kFold.split(X):\n",
    "\n",
    "    \n",
    "        X_train, X_test,y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "           \n",
    "        scaler = StandardScaler()\n",
    "\n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "        myclf = MyGradientBoostingClassifier(n_estimators=110,learning_rate=learning_rate,max_depth=7)\n",
    "\n",
    "\n",
    "        myclf.fit(X_train, y_train)\n",
    "\n",
    "        X_test = scaler.transform(X_test)\n",
    "        pred = myclf.predict(X_test)\n",
    "\n",
    "        res.append(accuracy_score(y_test, pred))\n",
    "\n",
    "    result.append((loss,learning_rate,np.mean(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('MSE', 0.05, 0.8346899224806201),\n",
       " ('MSE', 0.1, 0.8374031007751939),\n",
       " ('MSE', 0.3, 0.7715116279069767),\n",
       " ('MSE', 0.5, 0.6570251937984496)]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# colsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "kFold = KFold(n_splits=5, shuffle=False)\n",
    "result = []\n",
    "for colsample in [0.25, 0.5, 0.75, 1.0] :\n",
    "    res = []\n",
    "    for train, test in kFold.split(X):\n",
    "        \n",
    "        X_train, X_test,y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        \n",
    "        myclf = MyGradientBoostingClassifier(n_estimators=110,\n",
    "                                             colsample = colsample, \n",
    "                                             learning_rate=0.05,\n",
    "                                             max_depth=7)\n",
    "      \n",
    "            \n",
    "        myclf.fit(X_train, y_train)\n",
    "\n",
    "        X_test = scaler.transform(X_test)\n",
    "        pred = myclf.predict(X_test)\n",
    "        \n",
    "        res.append(accuracy_score(y_test, pred))\n",
    "        \n",
    "    result.append((colsample,np.mean(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.25, 0.8011143410852712),\n",
       " (0.5, 0.8276162790697674),\n",
       " (0.75, 0.8310562015503876),\n",
       " (1.0, 0.8417635658914728)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subsample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "kFold = KFold(n_splits=5, shuffle=False)\n",
    "result = []\n",
    "for subsample in [0.25, 0.5, 0.75, 1.0] :\n",
    "    res = []\n",
    "    for train, test in kFold.split(X):\n",
    "    \n",
    "        X_train, X_test,y_train, y_test = X[train], X[test], y[train], y[test]\n",
    "       \n",
    "        scaler = StandardScaler()\n",
    "        \n",
    "        X_train = scaler.fit_transform(X_train)\n",
    "        \n",
    "        myclf = MyGradientBoostingClassifier(n_estimators=110,\n",
    "                                             subsample = subsample, \n",
    "                                             colsample = 0.75,\n",
    "                                             learning_rate=0.05,\n",
    "                                             max_depth=7)\n",
    "      \n",
    "            \n",
    "        myclf.fit(X_train, y_train)\n",
    "\n",
    "        X_test = scaler.transform(X_test)\n",
    "        pred = myclf.predict(X_test)\n",
    "        \n",
    "        res.append(accuracy_score(y_test, pred))\n",
    "        \n",
    "    result.append((subsample,np.mean(res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.25, 0.831734496124031),\n",
       " (0.5, 0.8307170542635658),\n",
       " (0.75, 0.8363856589147286),\n",
       " (1.0, 0.8362403100775195)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Умная инициализация (1 балл)\n",
    "\n",
    "Попробуйте брать в качестве инициализации бустинга не константу, а какой-то алгоритм и уже от его предикта стартовать итерации бустинга. Попробуйте разные модели из sklearn: линейные модели, рандом форест, svm..\n",
    "\n",
    "Получилось ли улучшить качество? Почему?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X, y_1, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8881385789782736"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MyGradientBoostingClassifier(loss ='MSE', \n",
    "                                   n_estimators=110, \n",
    "                                   learning_rate=0.1, \n",
    "                                   max_depth= 5,\n",
    "                                   colsample=0.75,\n",
    "                                   subsample= 0.5)\n",
    "clf.fit(X_train, y_train, init_model=LinearRegression())\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8909277745155608"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MyGradientBoostingClassifier(loss ='MSE', \n",
    "                                   n_estimators=110, \n",
    "                                   learning_rate=0.1, \n",
    "                                   max_depth= 5,\n",
    "                                   colsample=0.75,\n",
    "                                   subsample= 0.5)\n",
    "clf.fit(X_train, y_train, init_model=SVC())\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8810921902524956"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MyGradientBoostingClassifier(loss ='MSE', \n",
    "                                   n_estimators=110, \n",
    "                                   learning_rate=0.1, \n",
    "                                   max_depth= 5,\n",
    "                                   colsample=0.75,\n",
    "                                   subsample= 0.5)\n",
    "clf.fit(X_train, y_train, init_model=RandomForestClassifier())\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8857897827363477"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MyGradientBoostingClassifier(loss ='EXP', \n",
    "                                   n_estimators=110, \n",
    "                                   learning_rate=0.1, \n",
    "                                   max_depth= 5,\n",
    "                                   colsample=0.75,\n",
    "                                   subsample= 0.5)\n",
    "clf.fit(X_train_1, y_train_1, init_model=LinearRegression())\n",
    "y_pred = clf.predict(X_test_1)\n",
    "accuracy_score(y_pred, y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.882413388138579"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MyGradientBoostingClassifier(loss ='EXP', \n",
    "                                   n_estimators=110, \n",
    "                                   learning_rate=0.1, \n",
    "                                   max_depth= 5,\n",
    "                                   colsample=0.75,\n",
    "                                   subsample= 0.5)\n",
    "clf.fit(X_train_1, y_train_1, init_model=SVC())\n",
    "y_pred = clf.predict(X_test_1)\n",
    "accuracy_score(y_pred, y_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8831473869641808"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MyGradientBoostingClassifier(loss ='EXP', \n",
    "                                   n_estimators=110, \n",
    "                                   learning_rate=0.1, \n",
    "                                   max_depth= 5,\n",
    "                                   colsample=0.75,\n",
    "                                   subsample= 0.5)\n",
    "clf.fit(X_train_1, y_train_1, init_model=RandomForestClassifier())\n",
    "y_pred = clf.predict(X_test_1)\n",
    "accuracy_score(y_pred, y_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы действительно улучшили score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие аспекты обучения  ансамблей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
