{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №3 - Дерево решений\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 08 декабря 2020, 08:30   \n",
    "**Штраф за опоздание:** -2 балла после 08:30 08 декабря, -4 балла после 08:30 15 декабря, -6 баллов после 08:30 22 декабря, -8 баллов после 08:30 29 декабря.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0220, Задание 3] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Реализуем дерево решений (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допишите недостающие части дерева решений. Ваша реализация дерева должна работать по точности не хуже DecisionTreeClassifier из sklearn.\n",
    "Внимание: если Вас не устраивает предложенная структура хранения дерева, Вы без потери баллов можете сделать свой класс DecisionTreeClassifier, в котором сами полностью воспроизведете алгоритм дерева решений. Обязательно в нем иметь только функции fit, predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import KFold, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyDecisionTreeClassifier:\n",
    "    NON_LEAF_TYPE = 0\n",
    "    LEAF_TYPE = 1\n",
    "\n",
    "    def __init__(self, min_samples_split=2,\n",
    "                 max_depth=None,\n",
    "                 sufficient_share=1.0,\n",
    "                 criterion='gini',\n",
    "                 max_features=None):\n",
    "\n",
    "        self.tree = dict()\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.max_depth = max_depth\n",
    "        self.sufficient_share = sufficient_share\n",
    "        self.num_class = -1\n",
    "        self.feature_importances_ = None\n",
    "\n",
    "        if criterion == 'entropy':\n",
    "            self.impurity = self.__entropy\n",
    "            self.feature = lambda y: - \\\n",
    "                ((np.bincount(y) / y.size) * np.log2(np.bincount(y) / y.size)).sum()\n",
    "        elif criterion == 'gini':\n",
    "            self.impurity = self.__gini\n",
    "            self.feature = lambda y: 1 - ((np.bincount(y) / y.size) ** 2).sum()\n",
    "        elif criterion == 'misclass':\n",
    "            self.impurity = self.__misclass\n",
    "            self.feature = lambda y: 1 - (np.bincount(y) / y.size).max()\n",
    "\n",
    "        if max_features == 'sqrt':\n",
    "            self.get_feature = self.get_feature_sqrt\n",
    "        elif max_features == 'log2':\n",
    "            self.get_feature = self.get_feature_log2\n",
    "        elif max_features is None:\n",
    "            self.get_feature = self.get_feature_n\n",
    "\n",
    "    def __gini(self, lc, ls, rc, rs):\n",
    "        ls = ls.astype('float')\n",
    "        rs = rs.astype('float')\n",
    "        return 1 - ((lc ** 2 / ls).sum(axis=1) + (rc ** 2 / rs).sum(axis=1)) / (ls[0] + rs[0])\n",
    "\n",
    "    def __entropy(self, lc, ls, rc, rs):\n",
    "        return -((lc * np.log2(lc / ls)).sum(axis=1) + (rc * np.log2(rc / rs)).sum(axis=1)) / (ls[0] + rs[0])\n",
    "\n",
    "    def __misclass(self, lc, ls, rc, rs):\n",
    "        return 1 - (lc.max(axis=1) + rc.max(axis=1)) / (ls[0] + rs[0])\n",
    "\n",
    "    def get_feature_sqrt(self, n):\n",
    "        feature = np.arange(n)\n",
    "        np.random.shuffle(feature)\n",
    "        return np.array(feature[: max(1, np.int(np.log2(n)))])\n",
    "\n",
    "    def get_feature_log2(self, n):\n",
    "        feature = np.arange(n)\n",
    "        np.random.shuffle(feature)\n",
    "        return np.array(feature[: max(1, np.int(np.sqrt(n)))])\n",
    "\n",
    "    def get_feature_n(self, n):\n",
    "        return np.arange(n)\n",
    "\n",
    "    def __div_samples(self, x, y, feature_id, threshold):\n",
    "        left_mask = x[:, feature_id] > threshold\n",
    "        right_mask = ~left_mask\n",
    "        return x[left_mask], x[right_mask], y[left_mask], y[right_mask]\n",
    "\n",
    "    def __sort_samples(self, x, y):\n",
    "        id_x = x.argsort()\n",
    "        return x[id_x], y[id_x]\n",
    "\n",
    "    def __find_threshold(self, x, y):\n",
    "\n",
    "        sorted_x, sorted_y = self.__sort_samples(x, y)\n",
    "        number = self.num_class\n",
    "        cut_size = np.int(self.min_samples_split / 2 - 1)\n",
    "\n",
    "        if cut_size == 0:\n",
    "            sp_y = sorted_y\n",
    "        else:\n",
    "            sp_y = sorted_y[cut_size:-cut_size]\n",
    "        bord = np.where(sp_y[:-1] != sp_y[1:])[0] + (cut_size + 1)\n",
    "\n",
    "        if len(bord) == 0:\n",
    "            return np.inf, None\n",
    "\n",
    "        eq_el_count = bord - np.append(np.array([cut_size]), bord[:-1])\n",
    "        one_hot_code = np.zeros((bord.shape[0], number))\n",
    "        one_hot_code[np.arange(bord.shape[0]), sorted_y[bord - 1]] = 1\n",
    "\n",
    "        increments = one_hot_code * eq_el_count.reshape(-1, 1)\n",
    "        increments[0] += np.bincount(sorted_y[:cut_size], minlength=number)\n",
    "\n",
    "        l_count = np.cumsum(increments, axis=0)\n",
    "        r_count = np.bincount(sorted_y, minlength=number) - l_count\n",
    "        l_sizes = bord.reshape(l_count.shape[0], 1)\n",
    "        r_sizes = sorted_y.shape[0] - l_sizes\n",
    "\n",
    "        G = self.impurity(l_count, l_sizes, r_count, r_sizes)\n",
    "        ind = np.argmin(G)\n",
    "        left = l_sizes[ind][0]\n",
    "\n",
    "        return G[ind], (sorted_x[left-1] + sorted_x[left]) / 2.0\n",
    "\n",
    "    def __fit_node(self, x, y, node_id, depth, pred_f=-1):\n",
    "        y_class_count = np.bincount(y)\n",
    "        y_class_max = y_class_count.argmax()\n",
    "        node_leaf = self.LEAF_TYPE, y_class_max, y_class_count / y.size\n",
    "\n",
    "        if (y.size < self.min_samples_split) or (depth == self.max_depth):\n",
    "            self.tree[node_id] = node_leaf\n",
    "            return\n",
    "        if y_class_count[y_class_max] >= y.size * self.sufficient_share:\n",
    "            self.tree[node_id] = node_leaf\n",
    "            return\n",
    "\n",
    "        features = self.get_feature(x.shape[1])\n",
    "        buf = np.array([self.__find_threshold(x[:, i], y) for i in features])\n",
    "        best_imp = buf[:, :1].argmin()\n",
    "        threshold = list(buf[best_imp]) + [best_imp]\n",
    "\n",
    "        Xleft, Xright, Yleft, Yright = self.__div_samples(\n",
    "            x, y, threshold[2], threshold[1])\n",
    "        if not Xleft.size or not Xright.size:\n",
    "            self.tree[node_id] = node_leaf\n",
    "        else:\n",
    "            self.tree[node_id] = self.NON_LEAF_TYPE, threshold[2], threshold[1]\n",
    "            self.feature_importances_[threshold[2]] += self.feature(y) * y.size\n",
    "            self.feature_importances_[\n",
    "                threshold[2]] -= (self.feature(Yleft) * Yleft.size + self.feature(Yright) * Yright.size)\n",
    "            self.__fit_node(Xleft, Yleft, 2 * node_id + 1, depth + 1, pred_f)\n",
    "            self.__fit_node(Xright, Yright, 2 * node_id + 2, depth + 1, pred_f)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.num_class = np.unique(y).size\n",
    "        self.feature_importances_ = np.zeros(x.shape[1])\n",
    "        self.__fit_node(x, y, 0, 0)\n",
    "        self.feature_importances_ /= self.feature_importances_.sum()\n",
    "\n",
    "    def __predict_class(self, x, node_id):\n",
    "        node = self.tree[node_id]\n",
    "        if node[0] == self.__class__.NON_LEAF_TYPE:\n",
    "            _, feature_id, threshold = node\n",
    "            if x[feature_id] > threshold:\n",
    "                return self.__predict_class(x, 2 * node_id + 1)\n",
    "            else:\n",
    "                return self.__predict_class(x, 2 * node_id + 2)\n",
    "        else:\n",
    "            return node[1]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.__predict_class(x, 0) for x in X])\n",
    "\n",
    "    def fit_predict(self, x_train, y_train, predicted_x):\n",
    "        self.fit(x_train, y_train)\n",
    "        return self.predict(predicted_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyDecisionTreeClassifier(min_samples_split=2)\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    wine.data, wine.target, test_size=0.1, stratify=wine.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_clf.fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred=clf.predict(X_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8888888888888888"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ускоряем дерево решений (2 балла)\n",
    "Добиться скорости работы на fit не медленнее чем в 10 раз sklearn на данных wine. \n",
    "Для этого используем numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.01 ms\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Боевое применение (3 балла)\n",
    "\n",
    "На практике Вы познакомились с датасетом Speed Dating Data. В нем каждая пара в быстрых свиданиях характеризуется определенным набором признаков. Задача -- предсказать, произойдет ли матч пары (колонка match). \n",
    "\n",
    "Пример работы с датасетом можете найти в практике пункт 2\n",
    "https://github.com/VVVikulin/ml1.sphere/blob/master/2019-09/lecture_06/pract-trees.ipynb\n",
    "\n",
    "Данные и описания колонок лежат тут\n",
    "https://cloud.mail.ru/public/8nHV/p6J7wY1y1/speed-dating-experiment/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачайте датасет, обработайте данные, как показано на семинаре или своим собственным способом. Обучите дерево классифкации. В качестве таргета возьмите колонку 'match'. Постарайтесь хорошо обработать признаки, чтобы выбить максимальную точность. Если точность будет близка к случайному гаданию, задание не будет защитано. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8378, 195)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Speed Dating Data.csv', sep=',', encoding=\"ISO-8859-1\")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим сколько NAN содержится в каждой из колонок, возьмем те, в которых NAN < 25**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.array([df.loc[(pd.isna(df[a])), a ].shape[0] for a in df.columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 23, 14, 12, 10,  9,  7, 97,  5,  4,  3,  2,  6,  1, 11],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = s.argsort()\n",
    "S[:s[s <= 25].shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['iid', 'dec_o', 'samerace', 'match', 'partner', 'order', 'position',\n",
       "       'dec', 'wave', 'condtn', 'idg', 'gender', 'round', 'id', 'pid'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = df.columns[S[:s[s <= 25].shape[0]]]\n",
    "cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[['match', 'iid', 'dec_o', 'samerace', 'partner', 'order',\n",
    "          'position', 'dec', 'wave', 'condtn', 'idg', 'gender', 'round', 'id', 'pid']]\n",
    "df2 = df2.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "men = df2[df2.gender == 1].drop_duplicates(subset=['iid', 'pid'])\n",
    "men = men.drop(['gender'], axis=1).dropna()\n",
    "\n",
    "women = df2[df2.gender == 0].drop_duplicates(subset=['iid'])\n",
    "women = women.drop(['gender', 'match', 'pid'], axis=1).dropna()\n",
    "women.columns = women.columns + '_woman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match</th>\n",
       "      <th>dec_o</th>\n",
       "      <th>samerace</th>\n",
       "      <th>partner</th>\n",
       "      <th>order</th>\n",
       "      <th>position</th>\n",
       "      <th>dec</th>\n",
       "      <th>wave</th>\n",
       "      <th>condtn</th>\n",
       "      <th>idg</th>\n",
       "      <th>...</th>\n",
       "      <th>samerace_woman</th>\n",
       "      <th>partner_woman</th>\n",
       "      <th>order_woman</th>\n",
       "      <th>position_woman</th>\n",
       "      <th>dec_woman</th>\n",
       "      <th>wave_woman</th>\n",
       "      <th>condtn_woman</th>\n",
       "      <th>idg_woman</th>\n",
       "      <th>round_woman</th>\n",
       "      <th>id_woman</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8289</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8311</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8333</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8355</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>22</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4183 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      match  dec_o  samerace  partner  order  position  dec  wave  condtn  \\\n",
       "100       0      1         0        1      4         7    0     1       1   \n",
       "110       0      1         0        1      3         7    0     1       1   \n",
       "120       1      1         1        1     10         7    1     1       1   \n",
       "130       1      1         0        1      5         7    1     1       1   \n",
       "140       1      1         0        1      7         7    1     1       1   \n",
       "...     ...    ...       ...      ...    ...       ...  ...   ...     ...   \n",
       "8267      0      0         0       22      9         2    0    21       2   \n",
       "8289      0      0         0       22     16         2    0    21       2   \n",
       "8311      0      1         0       22     18         2    0    21       2   \n",
       "8333      0      0         0       22      5         2    0    21       2   \n",
       "8355      0      0         0       22      4         2    0    21       2   \n",
       "\n",
       "      idg  ...  samerace_woman  partner_woman  order_woman  position_woman  \\\n",
       "100     2  ...               0              1            4               7   \n",
       "110     4  ...               0              1            4               7   \n",
       "120     6  ...               0              1            4               7   \n",
       "130     8  ...               0              1            4               7   \n",
       "140    10  ...               0              1            4               7   \n",
       "...   ...  ...             ...            ...          ...             ...   \n",
       "8267   34  ...               1              1           11               2   \n",
       "8289   36  ...               1              1           11               2   \n",
       "8311   38  ...               1              1           11               2   \n",
       "8333   40  ...               1              1           11               2   \n",
       "8355   42  ...               1              1           11               2   \n",
       "\n",
       "      dec_woman  wave_woman  condtn_woman  idg_woman  round_woman  id_woman  \n",
       "100           1           1             1          1           10       1.0  \n",
       "110           1           1             1          1           10       1.0  \n",
       "120           1           1             1          1           10       1.0  \n",
       "130           1           1             1          1           10       1.0  \n",
       "140           1           1             1          1           10       1.0  \n",
       "...         ...         ...           ...        ...          ...       ...  \n",
       "8267          1          21             2         43           22      22.0  \n",
       "8289          1          21             2         43           22      22.0  \n",
       "8311          1          21             2         43           22      22.0  \n",
       "8333          1          21             2         43           22      22.0  \n",
       "8355          1          21             2         43           22      22.0  \n",
       "\n",
       "[4183 rows x 23 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = men.join(women.set_index('iid_woman'), on='pid', how='inner')\n",
    "dfs = dfs.drop(['iid', 'pid'], axis=1)\n",
    "dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dfs.iloc[:, 1:].values\n",
    "y = dfs.iloc[:, 0].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)\n",
    "\n",
    "clf = DecisionTreeClassifier(min_samples_split=2)\n",
    "myclf = MyDecisionTreeClassifier(min_samples_split=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.99 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "%time myclf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=clf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_pred=myclf.predict(X_test), y_true=y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Находим самые важные признаки (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По построенному дереву  легко понять, какие признаки лучше всего помогли решить задачу. Часто это бывает нужно  не только  для сокращения размерности в данных, но и для лучшего понимания прикладной задачи. Например, Вы хотите понять, какие признаки стоит еще конструировать -- для этого нужно понимать, какие из текущих лучше всего работают в дереве. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самый простой метод -- посчитать число сплитов, где использовался данные признак. Это не лучший вариант, так как по признаку который принимает всего 2 значения, но который почти точно разделяет выборку, число сплитов будет очень 1, но при этом признак сам очень хороший. \n",
    "В этом задании предлагается для каждого признака считать суммарный gain (в лекции обозначено как Q) при использовании этого признака в сплите. Тогда даже у очень хороших признаков с маленьким число сплитов это значение должно быть довольно высоким.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализовать это довольно просто: создаете словарь номер фичи : суммарный гейн и добавляете в нужную фичу каждый раз, когда используете ее при построении дерева. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Добавьте функционал, который определяет значения feature importance. Обучите дерево на датасете Speed Dating Data.\n",
    "Выведите 10 главных фичей по важности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dec            0.659288\n",
       "dec_o          0.340712\n",
       "round_woman    0.000000\n",
       "samerace       0.000000\n",
       "partner        0.000000\n",
       "order          0.000000\n",
       "position       0.000000\n",
       "wave           0.000000\n",
       "condtn         0.000000\n",
       "idg            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(data=myclf.feature_importances_,\n",
    "          index=dfs.columns[1:]).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dec            0.659288\n",
       "dec_o          0.340712\n",
       "round_woman    0.000000\n",
       "samerace       0.000000\n",
       "partner        0.000000\n",
       "order          0.000000\n",
       "position       0.000000\n",
       "wave           0.000000\n",
       "condtn         0.000000\n",
       "idg            0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(data=clf.feature_importances_,\n",
    "          index=dfs.columns[1:]).sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие аспекты обучения деревьев решений Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Здесь Вы можете оставить отзыв о этой домашней работе или о всем курсе."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Материал доходчиво объяснен на целых трех семинарах это приятно, но пар стало очень много в последнее время))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
